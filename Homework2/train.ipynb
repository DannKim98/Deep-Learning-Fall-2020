{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([transforms.Resize(32),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.RandomVerticalFlip(),\n",
    "                                      transforms.RandomRotation(30),\n",
    "                                      transforms.RandomRotation(60),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "data = datasets.ImageFolder(data_dir, transform=train_transforms)\n",
    "train_data, val_data = torch.utils.data.random_split(data, [4000, 537])\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, 1)\n",
    "        self.fc1 = nn.Linear(64*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # define forward propagation here\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 64*5*5)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch+1, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/4000 (0%)]\tLoss: 2.332090\n",
      "Train Epoch: 1 [640/4000 (16%)]\tLoss: 1.240669\n",
      "Train Epoch: 1 [1280/4000 (32%)]\tLoss: 1.413548\n",
      "Train Epoch: 1 [1920/4000 (48%)]\tLoss: 1.291968\n",
      "Train Epoch: 1 [2560/4000 (63%)]\tLoss: 1.072481\n",
      "Train Epoch: 1 [3200/4000 (79%)]\tLoss: 1.028726\n",
      "Train Epoch: 1 [3840/4000 (95%)]\tLoss: 0.746496\n",
      "\n",
      "Test set: Average loss: 0.9117, Accuracy: 357/537 (66%)\n",
      "\n",
      "Train Epoch: 2 [0/4000 (0%)]\tLoss: 0.901478\n",
      "Train Epoch: 2 [640/4000 (16%)]\tLoss: 0.702296\n",
      "Train Epoch: 2 [1280/4000 (32%)]\tLoss: 0.564367\n",
      "Train Epoch: 2 [1920/4000 (48%)]\tLoss: 0.950831\n",
      "Train Epoch: 2 [2560/4000 (63%)]\tLoss: 0.980025\n",
      "Train Epoch: 2 [3200/4000 (79%)]\tLoss: 0.724869\n",
      "Train Epoch: 2 [3840/4000 (95%)]\tLoss: 0.446139\n",
      "\n",
      "Test set: Average loss: 0.7839, Accuracy: 376/537 (70%)\n",
      "\n",
      "Train Epoch: 3 [0/4000 (0%)]\tLoss: 0.717299\n",
      "Train Epoch: 3 [640/4000 (16%)]\tLoss: 0.962902\n",
      "Train Epoch: 3 [1280/4000 (32%)]\tLoss: 0.737634\n",
      "Train Epoch: 3 [1920/4000 (48%)]\tLoss: 0.866351\n",
      "Train Epoch: 3 [2560/4000 (63%)]\tLoss: 0.865044\n",
      "Train Epoch: 3 [3200/4000 (79%)]\tLoss: 0.809095\n",
      "Train Epoch: 3 [3840/4000 (95%)]\tLoss: 0.776834\n",
      "\n",
      "Test set: Average loss: 0.7220, Accuracy: 387/537 (72%)\n",
      "\n",
      "Train Epoch: 4 [0/4000 (0%)]\tLoss: 0.679155\n",
      "Train Epoch: 4 [640/4000 (16%)]\tLoss: 0.605881\n",
      "Train Epoch: 4 [1280/4000 (32%)]\tLoss: 0.739194\n",
      "Train Epoch: 4 [1920/4000 (48%)]\tLoss: 0.596087\n",
      "Train Epoch: 4 [2560/4000 (63%)]\tLoss: 0.707581\n",
      "Train Epoch: 4 [3200/4000 (79%)]\tLoss: 0.825704\n",
      "Train Epoch: 4 [3840/4000 (95%)]\tLoss: 0.729256\n",
      "\n",
      "Test set: Average loss: 0.7044, Accuracy: 395/537 (74%)\n",
      "\n",
      "Train Epoch: 5 [0/4000 (0%)]\tLoss: 0.542650\n",
      "Train Epoch: 5 [640/4000 (16%)]\tLoss: 0.782176\n",
      "Train Epoch: 5 [1280/4000 (32%)]\tLoss: 0.728847\n",
      "Train Epoch: 5 [1920/4000 (48%)]\tLoss: 0.523257\n",
      "Train Epoch: 5 [2560/4000 (63%)]\tLoss: 0.616931\n",
      "Train Epoch: 5 [3200/4000 (79%)]\tLoss: 0.613310\n",
      "Train Epoch: 5 [3840/4000 (95%)]\tLoss: 0.675801\n",
      "\n",
      "Test set: Average loss: 0.7135, Accuracy: 388/537 (72%)\n",
      "\n",
      "Train Epoch: 6 [0/4000 (0%)]\tLoss: 0.654150\n",
      "Train Epoch: 6 [640/4000 (16%)]\tLoss: 0.639637\n",
      "Train Epoch: 6 [1280/4000 (32%)]\tLoss: 0.801755\n",
      "Train Epoch: 6 [1920/4000 (48%)]\tLoss: 0.773603\n",
      "Train Epoch: 6 [2560/4000 (63%)]\tLoss: 0.481531\n",
      "Train Epoch: 6 [3200/4000 (79%)]\tLoss: 0.811517\n",
      "Train Epoch: 6 [3840/4000 (95%)]\tLoss: 0.604229\n",
      "\n",
      "Test set: Average loss: 0.6978, Accuracy: 391/537 (73%)\n",
      "\n",
      "Train Epoch: 7 [0/4000 (0%)]\tLoss: 0.583907\n",
      "Train Epoch: 7 [640/4000 (16%)]\tLoss: 0.597735\n",
      "Train Epoch: 7 [1280/4000 (32%)]\tLoss: 0.551913\n",
      "Train Epoch: 7 [1920/4000 (48%)]\tLoss: 0.670556\n",
      "Train Epoch: 7 [2560/4000 (63%)]\tLoss: 0.701635\n",
      "Train Epoch: 7 [3200/4000 (79%)]\tLoss: 0.653989\n",
      "Train Epoch: 7 [3840/4000 (95%)]\tLoss: 0.905870\n",
      "\n",
      "Test set: Average loss: 0.6963, Accuracy: 393/537 (73%)\n",
      "\n",
      "Train Epoch: 8 [0/4000 (0%)]\tLoss: 0.714226\n",
      "Train Epoch: 8 [640/4000 (16%)]\tLoss: 0.637045\n",
      "Train Epoch: 8 [1280/4000 (32%)]\tLoss: 0.487781\n",
      "Train Epoch: 8 [1920/4000 (48%)]\tLoss: 0.597521\n",
      "Train Epoch: 8 [2560/4000 (63%)]\tLoss: 0.654845\n",
      "Train Epoch: 8 [3200/4000 (79%)]\tLoss: 0.584255\n",
      "Train Epoch: 8 [3840/4000 (95%)]\tLoss: 0.674784\n",
      "\n",
      "Test set: Average loss: 0.6654, Accuracy: 400/537 (74%)\n",
      "\n",
      "Train Epoch: 9 [0/4000 (0%)]\tLoss: 0.491546\n",
      "Train Epoch: 9 [640/4000 (16%)]\tLoss: 0.642489\n",
      "Train Epoch: 9 [1280/4000 (32%)]\tLoss: 0.672079\n",
      "Train Epoch: 9 [1920/4000 (48%)]\tLoss: 0.869707\n",
      "Train Epoch: 9 [2560/4000 (63%)]\tLoss: 0.761259\n",
      "Train Epoch: 9 [3200/4000 (79%)]\tLoss: 0.741819\n",
      "Train Epoch: 9 [3840/4000 (95%)]\tLoss: 0.645780\n",
      "\n",
      "Test set: Average loss: 0.6551, Accuracy: 403/537 (75%)\n",
      "\n",
      "Train Epoch: 10 [0/4000 (0%)]\tLoss: 0.716825\n",
      "Train Epoch: 10 [640/4000 (16%)]\tLoss: 0.719947\n",
      "Train Epoch: 10 [1280/4000 (32%)]\tLoss: 0.650577\n",
      "Train Epoch: 10 [1920/4000 (48%)]\tLoss: 0.455586\n",
      "Train Epoch: 10 [2560/4000 (63%)]\tLoss: 0.636280\n",
      "Train Epoch: 10 [3200/4000 (79%)]\tLoss: 1.002015\n",
      "Train Epoch: 10 [3840/4000 (95%)]\tLoss: 0.875314\n",
      "\n",
      "Test set: Average loss: 0.6399, Accuracy: 404/537 (75%)\n",
      "\n",
      "Train Epoch: 11 [0/4000 (0%)]\tLoss: 0.660044\n",
      "Train Epoch: 11 [640/4000 (16%)]\tLoss: 0.611501\n",
      "Train Epoch: 11 [1280/4000 (32%)]\tLoss: 0.541635\n",
      "Train Epoch: 11 [1920/4000 (48%)]\tLoss: 0.738270\n",
      "Train Epoch: 11 [2560/4000 (63%)]\tLoss: 0.696822\n",
      "Train Epoch: 11 [3200/4000 (79%)]\tLoss: 0.648704\n",
      "Train Epoch: 11 [3840/4000 (95%)]\tLoss: 0.585634\n",
      "\n",
      "Test set: Average loss: 0.6574, Accuracy: 399/537 (74%)\n",
      "\n",
      "Train Epoch: 12 [0/4000 (0%)]\tLoss: 0.591480\n",
      "Train Epoch: 12 [640/4000 (16%)]\tLoss: 0.499617\n",
      "Train Epoch: 12 [1280/4000 (32%)]\tLoss: 0.622081\n",
      "Train Epoch: 12 [1920/4000 (48%)]\tLoss: 0.663373\n",
      "Train Epoch: 12 [2560/4000 (63%)]\tLoss: 0.517599\n",
      "Train Epoch: 12 [3200/4000 (79%)]\tLoss: 0.618302\n",
      "Train Epoch: 12 [3840/4000 (95%)]\tLoss: 0.514560\n",
      "\n",
      "Test set: Average loss: 0.6241, Accuracy: 409/537 (76%)\n",
      "\n",
      "Train Epoch: 13 [0/4000 (0%)]\tLoss: 0.392393\n",
      "Train Epoch: 13 [640/4000 (16%)]\tLoss: 0.701022\n",
      "Train Epoch: 13 [1280/4000 (32%)]\tLoss: 0.606607\n",
      "Train Epoch: 13 [1920/4000 (48%)]\tLoss: 0.489023\n",
      "Train Epoch: 13 [2560/4000 (63%)]\tLoss: 0.696018\n",
      "Train Epoch: 13 [3200/4000 (79%)]\tLoss: 0.822939\n",
      "Train Epoch: 13 [3840/4000 (95%)]\tLoss: 0.592743\n",
      "\n",
      "Test set: Average loss: 0.5991, Accuracy: 412/537 (77%)\n",
      "\n",
      "Train Epoch: 14 [0/4000 (0%)]\tLoss: 0.488186\n",
      "Train Epoch: 14 [640/4000 (16%)]\tLoss: 0.630933\n",
      "Train Epoch: 14 [1280/4000 (32%)]\tLoss: 0.519513\n",
      "Train Epoch: 14 [1920/4000 (48%)]\tLoss: 0.368669\n",
      "Train Epoch: 14 [2560/4000 (63%)]\tLoss: 0.530721\n",
      "Train Epoch: 14 [3200/4000 (79%)]\tLoss: 0.377177\n",
      "Train Epoch: 14 [3840/4000 (95%)]\tLoss: 0.664893\n",
      "\n",
      "Test set: Average loss: 0.5988, Accuracy: 419/537 (78%)\n",
      "\n",
      "Train Epoch: 15 [0/4000 (0%)]\tLoss: 0.532102\n",
      "Train Epoch: 15 [640/4000 (16%)]\tLoss: 0.445984\n",
      "Train Epoch: 15 [1280/4000 (32%)]\tLoss: 0.627721\n",
      "Train Epoch: 15 [1920/4000 (48%)]\tLoss: 0.509195\n",
      "Train Epoch: 15 [2560/4000 (63%)]\tLoss: 0.661354\n",
      "Train Epoch: 15 [3200/4000 (79%)]\tLoss: 0.643900\n",
      "Train Epoch: 15 [3840/4000 (95%)]\tLoss: 0.541098\n",
      "\n",
      "Test set: Average loss: 0.6026, Accuracy: 422/537 (79%)\n",
      "\n",
      "Train Epoch: 16 [0/4000 (0%)]\tLoss: 0.603798\n",
      "Train Epoch: 16 [640/4000 (16%)]\tLoss: 0.374166\n",
      "Train Epoch: 16 [1280/4000 (32%)]\tLoss: 0.675600\n",
      "Train Epoch: 16 [1920/4000 (48%)]\tLoss: 0.745226\n",
      "Train Epoch: 16 [2560/4000 (63%)]\tLoss: 0.611423\n",
      "Train Epoch: 16 [3200/4000 (79%)]\tLoss: 0.492226\n",
      "Train Epoch: 16 [3840/4000 (95%)]\tLoss: 0.608508\n",
      "\n",
      "Test set: Average loss: 0.6368, Accuracy: 410/537 (76%)\n",
      "\n",
      "Train Epoch: 17 [0/4000 (0%)]\tLoss: 0.526464\n",
      "Train Epoch: 17 [640/4000 (16%)]\tLoss: 0.350742\n",
      "Train Epoch: 17 [1280/4000 (32%)]\tLoss: 0.439534\n",
      "Train Epoch: 17 [1920/4000 (48%)]\tLoss: 0.626345\n",
      "Train Epoch: 17 [2560/4000 (63%)]\tLoss: 0.556770\n",
      "Train Epoch: 17 [3200/4000 (79%)]\tLoss: 0.606903\n",
      "Train Epoch: 17 [3840/4000 (95%)]\tLoss: 0.539795\n",
      "\n",
      "Test set: Average loss: 0.6557, Accuracy: 395/537 (74%)\n",
      "\n",
      "Train Epoch: 18 [0/4000 (0%)]\tLoss: 0.429039\n",
      "Train Epoch: 18 [640/4000 (16%)]\tLoss: 0.547913\n",
      "Train Epoch: 18 [1280/4000 (32%)]\tLoss: 0.413221\n",
      "Train Epoch: 18 [1920/4000 (48%)]\tLoss: 0.546242\n",
      "Train Epoch: 18 [2560/4000 (63%)]\tLoss: 0.379783\n",
      "Train Epoch: 18 [3200/4000 (79%)]\tLoss: 0.550996\n",
      "Train Epoch: 18 [3840/4000 (95%)]\tLoss: 0.751957\n",
      "\n",
      "Test set: Average loss: 0.6170, Accuracy: 409/537 (76%)\n",
      "\n",
      "Train Epoch: 19 [0/4000 (0%)]\tLoss: 0.635083\n",
      "Train Epoch: 19 [640/4000 (16%)]\tLoss: 0.381087\n",
      "Train Epoch: 19 [1280/4000 (32%)]\tLoss: 0.475885\n",
      "Train Epoch: 19 [1920/4000 (48%)]\tLoss: 0.511478\n",
      "Train Epoch: 19 [2560/4000 (63%)]\tLoss: 0.503520\n",
      "Train Epoch: 19 [3200/4000 (79%)]\tLoss: 0.505224\n",
      "Train Epoch: 19 [3840/4000 (95%)]\tLoss: 0.516864\n",
      "\n",
      "Test set: Average loss: 0.6142, Accuracy: 408/537 (76%)\n",
      "\n",
      "Train Epoch: 20 [0/4000 (0%)]\tLoss: 0.413846\n",
      "Train Epoch: 20 [640/4000 (16%)]\tLoss: 0.653660\n",
      "Train Epoch: 20 [1280/4000 (32%)]\tLoss: 0.780216\n",
      "Train Epoch: 20 [1920/4000 (48%)]\tLoss: 0.611494\n",
      "Train Epoch: 20 [2560/4000 (63%)]\tLoss: 0.447759\n",
      "Train Epoch: 20 [3200/4000 (79%)]\tLoss: 0.540217\n",
      "Train Epoch: 20 [3840/4000 (95%)]\tLoss: 0.492285\n",
      "\n",
      "Test set: Average loss: 0.6149, Accuracy: 412/537 (77%)\n",
      "\n",
      "Train Epoch: 21 [0/4000 (0%)]\tLoss: 0.702698\n",
      "Train Epoch: 21 [640/4000 (16%)]\tLoss: 0.416024\n",
      "Train Epoch: 21 [1280/4000 (32%)]\tLoss: 0.624212\n",
      "Train Epoch: 21 [1920/4000 (48%)]\tLoss: 0.542058\n",
      "Train Epoch: 21 [2560/4000 (63%)]\tLoss: 0.560309\n",
      "Train Epoch: 21 [3200/4000 (79%)]\tLoss: 0.267641\n",
      "Train Epoch: 21 [3840/4000 (95%)]\tLoss: 0.527217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5946, Accuracy: 411/537 (77%)\n",
      "\n",
      "Train Epoch: 22 [0/4000 (0%)]\tLoss: 0.606145\n",
      "Train Epoch: 22 [640/4000 (16%)]\tLoss: 0.590877\n",
      "Train Epoch: 22 [1280/4000 (32%)]\tLoss: 0.437505\n",
      "Train Epoch: 22 [1920/4000 (48%)]\tLoss: 0.506164\n",
      "Train Epoch: 22 [2560/4000 (63%)]\tLoss: 0.401581\n",
      "Train Epoch: 22 [3200/4000 (79%)]\tLoss: 0.419345\n",
      "Train Epoch: 22 [3840/4000 (95%)]\tLoss: 0.475409\n",
      "\n",
      "Test set: Average loss: 0.5825, Accuracy: 418/537 (78%)\n",
      "\n",
      "Train Epoch: 23 [0/4000 (0%)]\tLoss: 0.387221\n",
      "Train Epoch: 23 [640/4000 (16%)]\tLoss: 0.601162\n",
      "Train Epoch: 23 [1280/4000 (32%)]\tLoss: 0.623928\n",
      "Train Epoch: 23 [1920/4000 (48%)]\tLoss: 0.655793\n",
      "Train Epoch: 23 [2560/4000 (63%)]\tLoss: 0.455994\n",
      "Train Epoch: 23 [3200/4000 (79%)]\tLoss: 0.513008\n",
      "Train Epoch: 23 [3840/4000 (95%)]\tLoss: 0.371761\n",
      "\n",
      "Test set: Average loss: 0.6125, Accuracy: 411/537 (77%)\n",
      "\n",
      "Train Epoch: 24 [0/4000 (0%)]\tLoss: 0.531532\n",
      "Train Epoch: 24 [640/4000 (16%)]\tLoss: 0.530038\n",
      "Train Epoch: 24 [1280/4000 (32%)]\tLoss: 0.634042\n",
      "Train Epoch: 24 [1920/4000 (48%)]\tLoss: 0.288702\n",
      "Train Epoch: 24 [2560/4000 (63%)]\tLoss: 0.589348\n",
      "Train Epoch: 24 [3200/4000 (79%)]\tLoss: 0.367263\n",
      "Train Epoch: 24 [3840/4000 (95%)]\tLoss: 0.613042\n",
      "\n",
      "Test set: Average loss: 0.5645, Accuracy: 425/537 (79%)\n",
      "\n",
      "Train Epoch: 25 [0/4000 (0%)]\tLoss: 0.573517\n",
      "Train Epoch: 25 [640/4000 (16%)]\tLoss: 0.597458\n",
      "Train Epoch: 25 [1280/4000 (32%)]\tLoss: 0.389065\n",
      "Train Epoch: 25 [1920/4000 (48%)]\tLoss: 0.504481\n",
      "Train Epoch: 25 [2560/4000 (63%)]\tLoss: 0.417538\n",
      "Train Epoch: 25 [3200/4000 (79%)]\tLoss: 0.383118\n",
      "Train Epoch: 25 [3840/4000 (95%)]\tLoss: 0.491842\n",
      "\n",
      "Test set: Average loss: 0.5817, Accuracy: 415/537 (77%)\n",
      "\n",
      "Train Epoch: 26 [0/4000 (0%)]\tLoss: 0.368060\n",
      "Train Epoch: 26 [640/4000 (16%)]\tLoss: 0.572269\n",
      "Train Epoch: 26 [1280/4000 (32%)]\tLoss: 0.566492\n",
      "Train Epoch: 26 [1920/4000 (48%)]\tLoss: 0.431676\n",
      "Train Epoch: 26 [2560/4000 (63%)]\tLoss: 0.567430\n",
      "Train Epoch: 26 [3200/4000 (79%)]\tLoss: 0.537225\n",
      "Train Epoch: 26 [3840/4000 (95%)]\tLoss: 0.406424\n",
      "\n",
      "Test set: Average loss: 0.5826, Accuracy: 417/537 (78%)\n",
      "\n",
      "Train Epoch: 27 [0/4000 (0%)]\tLoss: 0.487836\n",
      "Train Epoch: 27 [640/4000 (16%)]\tLoss: 0.551937\n",
      "Train Epoch: 27 [1280/4000 (32%)]\tLoss: 0.652333\n",
      "Train Epoch: 27 [1920/4000 (48%)]\tLoss: 0.499328\n",
      "Train Epoch: 27 [2560/4000 (63%)]\tLoss: 0.412756\n",
      "Train Epoch: 27 [3200/4000 (79%)]\tLoss: 0.630772\n",
      "Train Epoch: 27 [3840/4000 (95%)]\tLoss: 0.395942\n",
      "\n",
      "Test set: Average loss: 0.5698, Accuracy: 418/537 (78%)\n",
      "\n",
      "Train Epoch: 28 [0/4000 (0%)]\tLoss: 0.604239\n",
      "Train Epoch: 28 [640/4000 (16%)]\tLoss: 0.485024\n",
      "Train Epoch: 28 [1280/4000 (32%)]\tLoss: 0.601003\n",
      "Train Epoch: 28 [1920/4000 (48%)]\tLoss: 0.422145\n",
      "Train Epoch: 28 [2560/4000 (63%)]\tLoss: 0.362321\n",
      "Train Epoch: 28 [3200/4000 (79%)]\tLoss: 0.561071\n",
      "Train Epoch: 28 [3840/4000 (95%)]\tLoss: 0.515216\n",
      "\n",
      "Test set: Average loss: 0.5796, Accuracy: 421/537 (78%)\n",
      "\n",
      "Train Epoch: 29 [0/4000 (0%)]\tLoss: 0.380585\n",
      "Train Epoch: 29 [640/4000 (16%)]\tLoss: 0.422796\n",
      "Train Epoch: 29 [1280/4000 (32%)]\tLoss: 0.392475\n",
      "Train Epoch: 29 [1920/4000 (48%)]\tLoss: 0.582780\n",
      "Train Epoch: 29 [2560/4000 (63%)]\tLoss: 0.680077\n",
      "Train Epoch: 29 [3200/4000 (79%)]\tLoss: 0.637121\n",
      "Train Epoch: 29 [3840/4000 (95%)]\tLoss: 0.477278\n",
      "\n",
      "Test set: Average loss: 0.5905, Accuracy: 406/537 (76%)\n",
      "\n",
      "Train Epoch: 30 [0/4000 (0%)]\tLoss: 0.453299\n",
      "Train Epoch: 30 [640/4000 (16%)]\tLoss: 0.478538\n",
      "Train Epoch: 30 [1280/4000 (32%)]\tLoss: 0.554484\n",
      "Train Epoch: 30 [1920/4000 (48%)]\tLoss: 0.546156\n",
      "Train Epoch: 30 [2560/4000 (63%)]\tLoss: 0.454597\n",
      "Train Epoch: 30 [3200/4000 (79%)]\tLoss: 0.543735\n",
      "Train Epoch: 30 [3840/4000 (95%)]\tLoss: 0.607817\n",
      "\n",
      "Test set: Average loss: 0.5994, Accuracy: 420/537 (78%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 30\n",
    "\n",
    "for epoch in range(epochs-20):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, val_loader)\n",
    "    \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "for epoch in range(epochs-20, epochs-10):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, val_loader)     \n",
    "    \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "for epoch in range(epochs-10, epochs):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, val_loader)\n",
    "\n",
    "torch.save(model.state_dict(),\"hw2_final1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
